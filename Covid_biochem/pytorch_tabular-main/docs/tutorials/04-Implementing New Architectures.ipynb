{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.datasets import make_regression\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\r\n",
    "import random\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import os\r\n",
    "try:\r\n",
    "  import google.colab\r\n",
    "  IN_COLAB = True\r\n",
    "except:\r\n",
    "  IN_COLAB = False\r\n",
    "if not IN_COLAB:\r\n",
    "    os.chdir(\"..\")\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utility Functions"
   ],
   "metadata": {
    "Collapsed": "true"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def make_mixed_regression(n_samples, n_features, n_categories):\r\n",
    "    X,y = make_regression(n_samples=n_samples, n_features=n_features, random_state=42, n_informative=5, n_targets=1)\r\n",
    "    cat_cols = random.choices(list(range(X.shape[-1])),k=n_categories)\r\n",
    "    num_cols = [i for i in range(X.shape[-1]) if i not in cat_cols]\r\n",
    "    for col in cat_cols:\r\n",
    "        X[:,col] = pd.qcut(X[:,col], q=4).codes.astype(int)\r\n",
    "    col_names = [] \r\n",
    "    num_col_names=[]\r\n",
    "    cat_col_names=[]\r\n",
    "    for i in range(X.shape[-1]):\r\n",
    "        if i in cat_cols:\r\n",
    "            col_names.append(f\"cat_col_{i}\")\r\n",
    "            cat_col_names.append(f\"cat_col_{i}\")\r\n",
    "        if i in num_cols:\r\n",
    "            col_names.append(f\"num_col_{i}\")\r\n",
    "            num_col_names.append(f\"num_col_{i}\")\r\n",
    "    X = pd.DataFrame(X, columns=col_names)\r\n",
    "    y = pd.DataFrame(y, columns=[\"target\"])\r\n",
    "    data = X.join(y)\r\n",
    "    return data, cat_col_names, num_col_names\r\n",
    "\r\n",
    "def print_metrics(y_true, y_pred, tag):\r\n",
    "    if isinstance(y_true, pd.DataFrame) or isinstance(y_true, pd.Series):\r\n",
    "        y_true = y_true.values\r\n",
    "    if isinstance(y_pred, pd.DataFrame) or isinstance(y_pred, pd.Series):\r\n",
    "        y_pred = y_pred.values\r\n",
    "    if y_true.ndim>1:\r\n",
    "        y_true=y_true.ravel()\r\n",
    "    if y_pred.ndim>1:\r\n",
    "        y_pred=y_pred.ravel()\r\n",
    "    val_acc = mean_squared_error(y_true, y_pred)\r\n",
    "    val_f1 = mean_absolute_error(y_true, y_pred)\r\n",
    "    print(f\"{tag} MSE: {val_acc} | {tag} MAE: {val_f1}\")"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate Synthetic Data \n",
    "\n",
    "First of all, let's create a synthetic data which is a mix of numerical and categorical features"
   ],
   "metadata": {
    "Collapsed": "true"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data, cat_col_names, num_col_names = make_mixed_regression(n_samples=10000, n_features=20, n_categories=4)\n",
    "train, test = train_test_split(data, random_state=42)\n",
    "train, val = train_test_split(train, random_state=42)"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing the Library"
   ],
   "metadata": {
    "Collapsed": "true"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig, ModelConfig\n",
    "from pytorch_tabular.models import BaseModel\n"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining a Custom Model"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from omegaconf import DictConfig\n",
    "from typing import Dict\n",
    "from dataclasses import dataclass, field"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "PyTorch Tabular is very easy to extend and infinitely customizable. All the models that have been implemented in PyTorch Tabular inherits an Abstract Class `BaseModel` which is in fact a PyTorchLightning Model.\n",
    "\n",
    "It handles all the major functions like decoding the config params and setting up the loss and metrics. It also calculates the Loss and metrics and feeds it back to the PyTorch Lightning Trainer which does the back-propagation.\n",
    "\n",
    "There are two methods that need to be defined in any class that inherits the Base Model:\n",
    "\n",
    "1. \\_build_network --> This is where you initialize the components required for your model to work\n",
    "2. forward --> This is the forward pass of the model.\n",
    "\n",
    "While this is the bare minimum, you can redefine or use any of the Pytorch Lightning standard methods to tweak your model and training to your liking.\n",
    "\n",
    "In addition to the model, you will also need to define a config. Configs are python dataclasses and should inherit `ModelConfig` and will have all the parameters of the ModelConfig. by default. Any additional parameter should be defined in the dataclass. \n",
    "\n",
    "\n",
    "**Key things to note:**\n",
    "\n",
    "1. All the different parameters in the different configs(like TrainerConfig, OptimizerConfig, etc) are all available in `config` before calling `super()` and in `self.hparams` after.\n",
    "2. the input batch at the `forward` method is a dictionary with keys `continuous` and `categorical`\n",
    "3. In the `\\_build_network` method, save every component that you want access in the `forward` to `self`\n",
    "4. The `forward` method should just have the forward pass and return the outut of the forward pass. In case of classification, do not apply a Sigmoid or Softmax at the end in the forward pass."
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "@dataclass\n",
    "class MyAwesomeModelConfig(ModelConfig):\n",
    "    use_batch_norm: bool = True\n",
    "        \n",
    "class MyAwesomeRegressionModel(BaseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: DictConfig,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # Save any attribute that you need in _build_network before calling super()\n",
    "        # The embedding_dims will be available in the config object and after the super() call, it will be available in self.hparams\n",
    "        self.embedding_cat_dim = sum([y for x, y in config.embedding_dims])\n",
    "        super().__init__(config, **kwargs)\n",
    "    \n",
    "    def _build_network(self):\n",
    "        self.embedding_layers = nn.ModuleList(\n",
    "            [nn.Embedding(x, y) for x, y in self.hparams.embedding_dims]\n",
    "        )\n",
    "        #Continuous and Categorical Dimensions are precalculated and stored in the config\n",
    "        inp_dim = self.embedding_cat_dim + self.hparams.continuous_dim\n",
    "        self.linear_layer_1 = nn.Linear(inp_dim, 200)\n",
    "        self.linear_layer_2 = nn.Linear(inp_dim+200, 70)\n",
    "        self.linear_layer_3 = nn.Linear(inp_dim+70, 1)\n",
    "        self.input_batch_norm = nn.BatchNorm1d(self.hparams.continuous_dim)\n",
    "        if self.hparams.use_batch_norm:\n",
    "            self.batch_norm_2 = nn.BatchNorm1d(inp_dim+200)\n",
    "            self.batch_norm_3 = nn.BatchNorm1d(inp_dim+70)\n",
    "        self.embedding_drop = nn.Dropout(0.6)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "    def forward(self, x: Dict):\n",
    "        continuous_data, categorical_data = x[\"continuous\"], x[\"categorical\"]\n",
    "        x = [\n",
    "                embedding_layer(categorical_data[:, i])\n",
    "                for i, embedding_layer in enumerate(self.embedding_layers)\n",
    "            ]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.embedding_drop(x)\n",
    "\n",
    "        continuous_data = self.input_batch_norm(continuous_data)\n",
    "        inp = torch.cat([x, continuous_data], 1)\n",
    "        x = F.relu(self.linear_layer_1(inp))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.cat([x,inp], 1)\n",
    "        if self.hparams.use_batch_norm:\n",
    "            x = self.batch_norm_1(x)\n",
    "        x = F.relu(self.linear_layer_2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.cat([x,inp], 1)\n",
    "        if self.hparams.use_batch_norm:\n",
    "            x = self.batch_norm_3(x)\n",
    "        x = self.linear_layer_3(x)\n",
    "        # target_range is a parameter defined in the ModelConfig and will be available in the config\n",
    "        if (\n",
    "            (self.hparams.task == \"regression\")\n",
    "            and (self.hparams.target_range is not None)\n",
    "        ):\n",
    "            for i in range(self.hparams.output_dim):\n",
    "                y_min, y_max = self.hparams.target_range[i]\n",
    "                x[:, i] = y_min + nn.Sigmoid()(x[:, i]) * (y_max - y_min)\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the Configs"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is one deviation from the normal when we create a TabularModel object with the configs. Earlier the model was inferred from the config and initialized autmatically. But here, we have to use the `model_callable` parameter of the TabularModel and pass in the model class(not the initialized object)"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_config = DataConfig(\n",
    "    target=['target'], #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=num_col_names,\n",
    "    categorical_cols=cat_col_names,\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=1024,\n",
    "    max_epochs=100,\n",
    "    gpus=-1,  #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "model_config = MyAwesomeModelConfig(\n",
    "    task=\"regression\",\n",
    "    use_batch_norm =False,\n",
    "    learning_rate = 1e-3\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    "    model_callable = MyAwesomeRegressionModel\n",
    ")"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the Model \n",
    "\n",
    "The rest of the process is business-as-usual"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tabular_model.fit(train=train, validation=val)"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false",
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "result = tabular_model.evaluate(test)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40224f0d08024eeb9e75e081a9fe301f",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_mean_squared_error': tensor(14005.2725, device='cuda:0'),\n",
      " 'train_loss': tensor(3013.1719, device='cuda:0'),\n",
      " 'train_mean_squared_error': tensor(15613.8184, device='cuda:0'),\n",
      " 'valid_loss': tensor(1060.1337, device='cuda:0'),\n",
      " 'valid_mean_squared_error': tensor(15130.5811, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "pred_df = tabular_model.predict(test)\n",
    "pred_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      num_col_0  cat_col_1  num_col_2  num_col_3  num_col_4  num_col_5  \\\n",
       "6252   0.321476        0.0  -0.836426  -0.200794  -1.372801   0.148776   \n",
       "4684   0.291679        1.0  -0.213108   1.888767   1.209858  -0.684209   \n",
       "1731  -1.547951        1.0   1.517188  -0.638986   2.356890   0.826815   \n",
       "4742   0.911628        3.0   0.089328  -0.304067   0.984190  -1.114405   \n",
       "4521   0.087945        2.0  -0.320962  -0.231244   0.423397  -0.512270   \n",
       "\n",
       "      num_col_6  num_col_7  num_col_8  num_col_9  ...  cat_col_12  num_col_13  \\\n",
       "6252   1.607678  -0.710938   0.099704   2.494107  ...         2.0    2.410212   \n",
       "4684   0.065715  -1.661187  -2.164594  -1.212303  ...         1.0    1.778092   \n",
       "1731  -0.570187  -0.415643   0.787585   0.027579  ...         2.0   -0.324598   \n",
       "4742   0.594178  -0.785370  -0.994555  -0.379163  ...         2.0   -0.217751   \n",
       "4521  -0.314670  -0.440412  -0.386701   0.966912  ...         3.0    1.654840   \n",
       "\n",
       "      cat_col_14  num_col_15  num_col_16  cat_col_17  num_col_18  num_col_19  \\\n",
       "6252         0.0   -0.416442   -0.843505         2.0    0.150040   -0.636704   \n",
       "4684         0.0   -1.007395    0.304803         2.0   -0.638452    0.672491   \n",
       "1731         2.0    1.993319    0.028488         1.0    1.121574   -0.146075   \n",
       "4742         0.0   -1.001061   -0.725295         0.0   -0.511682   -0.721897   \n",
       "4521         3.0    1.296487    1.079245         3.0    0.327339   -0.365532   \n",
       "\n",
       "          target  target_prediction  \n",
       "6252 -119.618988        -174.084061  \n",
       "4684 -207.596232        -171.813644  \n",
       "1731  272.098656         198.954025  \n",
       "4742   21.896867         106.040825  \n",
       "4521   46.346326          51.485107  \n",
       "\n",
       "[5 rows x 22 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col_0</th>\n",
       "      <th>cat_col_1</th>\n",
       "      <th>num_col_2</th>\n",
       "      <th>num_col_3</th>\n",
       "      <th>num_col_4</th>\n",
       "      <th>num_col_5</th>\n",
       "      <th>num_col_6</th>\n",
       "      <th>num_col_7</th>\n",
       "      <th>num_col_8</th>\n",
       "      <th>num_col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>cat_col_12</th>\n",
       "      <th>num_col_13</th>\n",
       "      <th>cat_col_14</th>\n",
       "      <th>num_col_15</th>\n",
       "      <th>num_col_16</th>\n",
       "      <th>cat_col_17</th>\n",
       "      <th>num_col_18</th>\n",
       "      <th>num_col_19</th>\n",
       "      <th>target</th>\n",
       "      <th>target_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>0.321476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.836426</td>\n",
       "      <td>-0.200794</td>\n",
       "      <td>-1.372801</td>\n",
       "      <td>0.148776</td>\n",
       "      <td>1.607678</td>\n",
       "      <td>-0.710938</td>\n",
       "      <td>0.099704</td>\n",
       "      <td>2.494107</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.410212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.416442</td>\n",
       "      <td>-0.843505</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.150040</td>\n",
       "      <td>-0.636704</td>\n",
       "      <td>-119.618988</td>\n",
       "      <td>-174.084061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>0.291679</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.213108</td>\n",
       "      <td>1.888767</td>\n",
       "      <td>1.209858</td>\n",
       "      <td>-0.684209</td>\n",
       "      <td>0.065715</td>\n",
       "      <td>-1.661187</td>\n",
       "      <td>-2.164594</td>\n",
       "      <td>-1.212303</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.778092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.007395</td>\n",
       "      <td>0.304803</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.638452</td>\n",
       "      <td>0.672491</td>\n",
       "      <td>-207.596232</td>\n",
       "      <td>-171.813644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>-1.547951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.517188</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>2.356890</td>\n",
       "      <td>0.826815</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.415643</td>\n",
       "      <td>0.787585</td>\n",
       "      <td>0.027579</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.324598</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.993319</td>\n",
       "      <td>0.028488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.121574</td>\n",
       "      <td>-0.146075</td>\n",
       "      <td>272.098656</td>\n",
       "      <td>198.954025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>0.911628</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.089328</td>\n",
       "      <td>-0.304067</td>\n",
       "      <td>0.984190</td>\n",
       "      <td>-1.114405</td>\n",
       "      <td>0.594178</td>\n",
       "      <td>-0.785370</td>\n",
       "      <td>-0.994555</td>\n",
       "      <td>-0.379163</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.217751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.001061</td>\n",
       "      <td>-0.725295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.511682</td>\n",
       "      <td>-0.721897</td>\n",
       "      <td>21.896867</td>\n",
       "      <td>106.040825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>0.087945</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.320962</td>\n",
       "      <td>-0.231244</td>\n",
       "      <td>0.423397</td>\n",
       "      <td>-0.512270</td>\n",
       "      <td>-0.314670</td>\n",
       "      <td>-0.440412</td>\n",
       "      <td>-0.386701</td>\n",
       "      <td>0.966912</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.654840</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.296487</td>\n",
       "      <td>1.079245</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.327339</td>\n",
       "      <td>-0.365532</td>\n",
       "      <td>46.346326</td>\n",
       "      <td>51.485107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print_metrics(test['target'], pred_df[\"target_prediction\"], tag=\"Holdout\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Holdout MSE: 2515.075280931874 | Holdout MAE: 38.42137329388225\n"
     ]
    }
   ],
   "metadata": {
    "Collapsed": "false"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:df_encoder]",
   "language": "python",
   "name": "conda-env-df_encoder-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}