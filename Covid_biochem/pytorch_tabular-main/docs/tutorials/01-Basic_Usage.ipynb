{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.datasets import make_classification\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import accuracy_score, f1_score\r\n",
    "import random\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import os\r\n",
    "try:\r\n",
    "  import google.colab\r\n",
    "  IN_COLAB = True\r\n",
    "except:\r\n",
    "  IN_COLAB = False\r\n",
    "if not IN_COLAB:\r\n",
    "    os.chdir(\"..\")\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utility Functions"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def make_mixed_classification(n_samples, n_features, n_categories):\r\n",
    "    X,y = make_classification(n_samples=n_samples, n_features=n_features, random_state=42, n_informative=5)\r\n",
    "    cat_cols = random.choices(list(range(X.shape[-1])),k=n_categories)\r\n",
    "    num_cols = [i for i in range(X.shape[-1]) if i not in cat_cols]\r\n",
    "    for col in cat_cols:\r\n",
    "        X[:,col] = pd.qcut(X[:,col], q=4).codes.astype(int)\r\n",
    "    col_names = [] \r\n",
    "    num_col_names=[]\r\n",
    "    cat_col_names=[]\r\n",
    "    for i in range(X.shape[-1]):\r\n",
    "        if i in cat_cols:\r\n",
    "            col_names.append(f\"cat_col_{i}\")\r\n",
    "            cat_col_names.append(f\"cat_col_{i}\")\r\n",
    "        if i in num_cols:\r\n",
    "            col_names.append(f\"num_col_{i}\")\r\n",
    "            num_col_names.append(f\"num_col_{i}\")\r\n",
    "    X = pd.DataFrame(X, columns=col_names)\r\n",
    "    y = pd.Series(y, name=\"target\")\r\n",
    "    data = X.join(y)\r\n",
    "    return data, cat_col_names, num_col_names\r\n",
    "\r\n",
    "def print_metrics(y_true, y_pred, tag):\r\n",
    "    if isinstance(y_true, pd.DataFrame) or isinstance(y_true, pd.Series):\r\n",
    "        y_true = y_true.values\r\n",
    "    if isinstance(y_pred, pd.DataFrame) or isinstance(y_pred, pd.Series):\r\n",
    "        y_pred = y_pred.values\r\n",
    "    if y_true.ndim>1:\r\n",
    "        y_true=y_true.ravel()\r\n",
    "    if y_pred.ndim>1:\r\n",
    "        y_pred=y_pred.ravel()\r\n",
    "    val_acc = accuracy_score(y_true, y_pred)\r\n",
    "    val_f1 = f1_score(y_true, y_pred)\r\n",
    "    print(f\"{tag} Acc: {val_acc} | {tag} F1: {val_f1}\")"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate Synthetic Data \n",
    "\n",
    "First of all, let's create a synthetic data which is a mix of numerical and categorical features"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "data, cat_col_names, num_col_names = make_mixed_classification(n_samples=10000, n_features=20, n_categories=4)\n",
    "train, test = train_test_split(data, random_state=42)\n",
    "train, val = train_test_split(train, random_state=42)"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing the Library"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the Configs\n",
    "\n",
    "This is the most crucial step in the process. There are four configs that you need to provide(most of them have intelligent default values), which will drive the rest of the process.\n",
    "\n",
    "* DataConfig - Define the target column names, categorical and numerical column names, any transformation you need to do, etc.\n",
    "* ModelConfig - There is a specific config for each of the models. This determines which model we are going to train and also lets you define the hyperparameters of the model\n",
    "* TrainerConfig - This let's you configure the training process by setting things like batch_size, epochs, early stopping, etc. The vast majority of parameters are directly borrowed from PyTorch Lightning and is passed to the underlying Trainer object during training\n",
    "* OptimizerConfig - This let's you define and use different Optimizers and LearningRate Schedulers. Standard PyTorch Optimizers and Learning RateSchedulers are supported. For custom optimizers, you can use the parameter in the fit method to overwrite this. The custom optimizer should be PyTorch compatible\n",
    "* ExperimentConfig - This is an optional parameter. If set, this defines the Experiment Tracking. Right now, only two experiment tracking frameworks are supported: Tensorboard and Weights&Biases. W&B experiment tracker has more features like tracking the gradients and logits across epochs."
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "data_config = DataConfig(\n",
    "    target=['target'], #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=num_col_names,\n",
    "    categorical_cols=cat_col_names,\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=1024,\n",
    "    max_epochs=100,\n",
    "    gpus=-1, #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"classification\",\n",
    "    layers=\"1024-512-512\",  # Number of nodes in each layer\n",
    "    activation=\"LeakyReLU\", # Activation between each layers\n",
    "    learning_rate = 1e-3\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the Model \n",
    "Now that we have defined the configs and the TabularModel. We just need to call the `fit` method and pass the train and test dataframes. We can also pass in validation dataframe. But if omitted, TabularModel will separate 20%(also configurable) at random from the data as validation.\n",
    "\n",
    "By default, EarlyStopping is enabled and is monitoring Validation Loss with a patience of 3 epochs. The trainer also saves the best model(based on validation loss) and loads that model at the end of training. `TrainerConfig` has the parameters to tweak this default behaviour."
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tabular_model.fit(train=train, validation=val)"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false",
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating the Model"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loss and Metrics on New Data\n",
    "To evaluate the model on new data on the same metrics/loss that was used during training, we can use the `evaluate` method"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "result = tabular_model.evaluate(test)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=â€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc646cf1935941eaba72b98e8b139145",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_accuracy': tensor(0.6924, device='cuda:0'),\n",
      " 'train_accuracy': tensor(0.6051, device='cuda:0'),\n",
      " 'train_loss': tensor(0.6258, device='cuda:0'),\n",
      " 'valid_accuracy': tensor(0.7440, device='cuda:0'),\n",
      " 'valid_loss': tensor(0.5769, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## New Predictions as DataFrame\n",
    "To get the prediction as a dataframe, we can use the `predict` method. This will add predictions to the same dataframe that was passed in. For classification problems, we get both the probabilities and the final prediction taking 0.5 as the threshold"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "pred_df = tabular_model.predict(test)\n",
    "pred_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      num_col_0  num_col_1  num_col_2  num_col_3  num_col_4  num_col_5  \\\n",
       "6252  -2.790932  -3.304646  -2.010758   3.205420  -0.356361  -0.744417   \n",
       "4684  -0.139585  -1.360640  -1.207160   2.690514   1.072764  -3.499028   \n",
       "1731   0.001421  -0.046718  -0.279572   0.363639   0.852329   0.089246   \n",
       "4742   0.086662   1.549718   0.798527   0.916448  -1.085978   0.512223   \n",
       "4521   0.982186   0.909692  -0.117476  -0.168583  -0.088413  -0.206658   \n",
       "\n",
       "      cat_col_6  num_col_7  num_col_8  num_col_9  ...  num_col_14  num_col_15  \\\n",
       "6252        2.0  -1.492040  -1.061102   1.364186  ...   -0.660336   -0.705788   \n",
       "4684        3.0   0.953991   0.439317   1.243788  ...   -2.726836    0.944248   \n",
       "1731        2.0   0.194984  -1.005871   2.668561  ...   -0.508633    0.508788   \n",
       "4742        0.0   1.538725   0.475361   1.518521  ...    0.326685    1.343219   \n",
       "4521        0.0  -0.137569   1.253686  -1.678887  ...   -0.282845    0.458761   \n",
       "\n",
       "      num_col_16  cat_col_17  num_col_18  num_col_19  target  0_probability  \\\n",
       "6252    0.229519         2.0   -0.464394    2.879481       0       0.549150   \n",
       "4684    0.821184         2.0   -1.199147    0.126323       1       0.868879   \n",
       "1731   -0.097083         1.0   -0.282642   -0.190155       0       0.331293   \n",
       "4742   -1.147619         3.0    0.857619    0.532915       1       0.809316   \n",
       "4521    1.381926         1.0   -0.475947   -0.400418       1       0.695432   \n",
       "\n",
       "      1_probability  prediction  \n",
       "6252       0.450850           0  \n",
       "4684       0.131121           0  \n",
       "1731       0.668707           1  \n",
       "4742       0.190684           0  \n",
       "4521       0.304568           0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col_0</th>\n",
       "      <th>num_col_1</th>\n",
       "      <th>num_col_2</th>\n",
       "      <th>num_col_3</th>\n",
       "      <th>num_col_4</th>\n",
       "      <th>num_col_5</th>\n",
       "      <th>cat_col_6</th>\n",
       "      <th>num_col_7</th>\n",
       "      <th>num_col_8</th>\n",
       "      <th>num_col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>num_col_14</th>\n",
       "      <th>num_col_15</th>\n",
       "      <th>num_col_16</th>\n",
       "      <th>cat_col_17</th>\n",
       "      <th>num_col_18</th>\n",
       "      <th>num_col_19</th>\n",
       "      <th>target</th>\n",
       "      <th>0_probability</th>\n",
       "      <th>1_probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>-2.790932</td>\n",
       "      <td>-3.304646</td>\n",
       "      <td>-2.010758</td>\n",
       "      <td>3.205420</td>\n",
       "      <td>-0.356361</td>\n",
       "      <td>-0.744417</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.492040</td>\n",
       "      <td>-1.061102</td>\n",
       "      <td>1.364186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660336</td>\n",
       "      <td>-0.705788</td>\n",
       "      <td>0.229519</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.464394</td>\n",
       "      <td>2.879481</td>\n",
       "      <td>0</td>\n",
       "      <td>0.549150</td>\n",
       "      <td>0.450850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>-0.139585</td>\n",
       "      <td>-1.360640</td>\n",
       "      <td>-1.207160</td>\n",
       "      <td>2.690514</td>\n",
       "      <td>1.072764</td>\n",
       "      <td>-3.499028</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.953991</td>\n",
       "      <td>0.439317</td>\n",
       "      <td>1.243788</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.726836</td>\n",
       "      <td>0.944248</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.199147</td>\n",
       "      <td>0.126323</td>\n",
       "      <td>1</td>\n",
       "      <td>0.868879</td>\n",
       "      <td>0.131121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>0.001421</td>\n",
       "      <td>-0.046718</td>\n",
       "      <td>-0.279572</td>\n",
       "      <td>0.363639</td>\n",
       "      <td>0.852329</td>\n",
       "      <td>0.089246</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.194984</td>\n",
       "      <td>-1.005871</td>\n",
       "      <td>2.668561</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508633</td>\n",
       "      <td>0.508788</td>\n",
       "      <td>-0.097083</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.282642</td>\n",
       "      <td>-0.190155</td>\n",
       "      <td>0</td>\n",
       "      <td>0.331293</td>\n",
       "      <td>0.668707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>0.086662</td>\n",
       "      <td>1.549718</td>\n",
       "      <td>0.798527</td>\n",
       "      <td>0.916448</td>\n",
       "      <td>-1.085978</td>\n",
       "      <td>0.512223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.538725</td>\n",
       "      <td>0.475361</td>\n",
       "      <td>1.518521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326685</td>\n",
       "      <td>1.343219</td>\n",
       "      <td>-1.147619</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.857619</td>\n",
       "      <td>0.532915</td>\n",
       "      <td>1</td>\n",
       "      <td>0.809316</td>\n",
       "      <td>0.190684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>0.982186</td>\n",
       "      <td>0.909692</td>\n",
       "      <td>-0.117476</td>\n",
       "      <td>-0.168583</td>\n",
       "      <td>-0.088413</td>\n",
       "      <td>-0.206658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.137569</td>\n",
       "      <td>1.253686</td>\n",
       "      <td>-1.678887</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.282845</td>\n",
       "      <td>0.458761</td>\n",
       "      <td>1.381926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.475947</td>\n",
       "      <td>-0.400418</td>\n",
       "      <td>1</td>\n",
       "      <td>0.695432</td>\n",
       "      <td>0.304568</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print_metrics(test['target'], pred_df[\"prediction\"], tag=\"Holdout\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Holdout Acc: 0.6 | Holdout F1: 0.5575221238938053\n"
     ]
    }
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving and Loading the Model"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "tabular_model.save_model(\"examples/basic\")"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loaded_model = TabularModel.load_from_checkpoint(\"examples/basic\")"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "result = loaded_model.evaluate(test)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=â€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf8134b19684167aaeb346d98f35bb5",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_accuracy': tensor(0.6924, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "Collapsed": "false"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:df_encoder]",
   "language": "python",
   "name": "conda-env-df_encoder-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}